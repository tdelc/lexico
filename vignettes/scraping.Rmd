---
title: "Scraper des playlists YouTube"
author: "lexico"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Scraper des playlists YouTube}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

Cette vignette décrit comment récupérer des vidéos et des sous-titres
YouTube avant de les transformer en tableaux exploitables avec le package
**lexico**.

## Pré-requis

- Une clé API YouTube (`YT_API_KEY`).
- L'outil en ligne de commande `yt-dlp`, indiqué via `yt_dlp_path`.
- Un dossier où stocker les CSV et les sous-titres téléchargés.

## Récupérer les métadonnées de playlist

Les fonctions `get_playlist_items()` et `get_videos_details()` permettent
respectivement de récupérer la liste des vidéos et leurs statistiques.

```{r playlist}
library(lexico)

yt_dlp_path  <- Sys.getenv("YT_DLP_PATH")
api_key <- Sys.getenv("YT_API_KEY")

playlist_id <- "PLg6GanYvTasW3tTMej4dqF65OBYud7vpr"

# 1. Liste des vidéos (titre, date de publication, etc.)
df_info <- get_playlist_items(api_key, playlist_id, max_results = 20)

# 2. Statistiques associées (langue, durée, vues, likes...)
df_stat <- get_videos_details(api_key, df_info$video_id)
```

## Télécharger et convertir les sous-titres

`download_subtitles()` s'appuie sur `yt-dlp` pour récupérer les sous-titres
automatiques en français. 

```{r}
# Dossier de travail où seront créés le fichier de sous-titre
workdir <- file.path(tempdir(),"data")
dir.create(workdir, showWarnings = FALSE)

video_id <- "OwJFgUMeVl0"

download_subtitles(video_id = video_id,
                   out_dir = workdir,
                   yt_dlp = yt_dlp_path,
                   force_dl = FALSE)
```
La fonction `run_complete_extraction()` combine
toutes les étapes (métadonnées + sous-titres + sauvegarde CSV).

```{r download}
# Dossier de travail où seront créés df_info_*, df_stat_* et df_text_*
workdir <- file.path(tempdir(),"data")
dir.create(workdir, showWarnings = FALSE)

run_complete_extraction(
  api_key = api_key,
  yt_dlp_path = yt_dlp_path,
  path = workdir,
  suffix = "playlist_demo",
  playlist_id = playlist_id,
  max_videos = 20
)
```

Voici le processus général :

```{r}
library(lexico)
yt_dlp  <- Sys.getenv("YT_DLP_PATH")
api_key <- Sys.getenv("YT_API_KEY")

max_videos  <- 10
workdir <- file.path(tempdir(),"data")

df_playlist <- dplyr::tibble(
                 suffix = "bfm",
                 channelTitle = "BFMTV",
                 playlist_id = "PL-qBKb-rfbhjZjW0RQr3Dm8iIvXFE0Gwy",
                 playlistDescription = "Politique") %>%
  dplyr::add_row(suffix = "fra",
                 channelTitle = "franceinfo",
                 playlist_id = "PLg6GanYvTasWQv6EPyPInaYhtyFRcht3r",
                 playlistDescription = "Interview de 8:30")

1:nrow(df_playlist) %>% purrr::map(~{
  row <- df_playlist[.x,]
  cli::cli_alert_info("Extraction {row$playlistDescription}")
  run_complete_extraction(api_key,yt_dlp,raw_path,
                          row$suffix,row$playlist_id,max_videos)
})

```


Les sous-titres bruts peuvent être convertis :

```{r convert}
path_vtt <- file.path(workdir,paste0(video_id,".fr.vtt"))

# Obtenir un tableau horodaté
minute_df <- read_vtt_as_df_fast(path_vtt)
```

## Regrouper par minutes

Pour regrouper et obtenir une seule ligne de texte.

```{r}
minute_df %>% 
  group_by(video_id) %>% 
  summarise(text = paste(text,collapse = " "))
```

Pour des analyses temporelles ou des extractions plus compactes,
`group_minuted_text()` regroupe les segments par tranches de *n* minutes.

```{r grouping}
minute_df |>
  group_minuted_text(minutes = 1, video_id = "video_id")
```

Cette sortie peut ensuite être nettoyée et enrichie avant d'être utilisée
dans les autres vignettes (préparation, IRaMuTeQ, Quanteda).
