---
title: "Scraper des playlists YouTube"
author: "lexico"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Scraper des playlists YouTube}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = T
)
```

Cette vignette décrit comment récupérer des vidéos et des sous-titres
YouTube avant de les transformer en tableaux exploitables avec le package
**lexico**.

## Pré-requis

- Une clé API YouTube (`YT_API_KEY`).
- L'outil en ligne de commande `yt-dlp`, indiqué via `yt_dlp_path`.
- Un dossier où stocker les CSV et les sous-titres téléchargés.

## Récupérer les métadonnées de playlist

Les fonctions `get_playlist_items()` et `get_videos_details()` permettent
respectivement de récupérer la liste des vidéos et leurs statistiques.

```{r playlist}
library(lexico)
library(dplyr)

yt_dlp_path  <- Sys.getenv("YT_DLP_PATH")
api_key <- Sys.getenv("YT_API_KEY")

playlist_id <- "PLg6GanYvTasW3tTMej4dqF65OBYud7vpr"

# 1. Liste des vidéos (titre, date de publication, etc.)
df_info <- get_playlist_items(api_key, playlist_id, max_results = 20)

# 2. Statistiques associées (langue, durée, vues, likes...)
df_stat <- get_videos_details(api_key, df_info$video_id)

head(df_info)
head(df_stat)
```

## Télécharger et convertir les sous-titres

`download_subtitles()` s'appuie sur `yt-dlp` pour récupérer les sous-titres
automatiques en français. 

```{r}
# Dossier de travail où seront créés le fichier de sous-titre
workdir <- file.path(tempdir(),"data")
dir.create(workdir, showWarnings = FALSE)

video_id <- "OwJFgUMeVl0"

download_subtitles(video_id = video_id,
                   out_dir = workdir,
                   yt_dlp = yt_dlp_path,
                   force_dl = FALSE)
```
La fonction `run_complete_extraction()` combine
toutes les étapes (métadonnées + sous-titres + sauvegarde CSV).

```{r download, eval = FALSE}
# Dossier de travail où seront créés df_info_*, df_stat_* et df_text_*
workdir <- file.path(tempdir(),"data")
dir.create(workdir, showWarnings = FALSE)

run_complete_extraction(
  api_key = api_key,
  yt_dlp_path = yt_dlp_path,
  path = workdir,
  suffix = "playlist_demo",
  playlist_id = playlist_id,
  max_videos = 5
)

df_text <- read.csv(file.path(workdir,"df_text_playlist_demo.csv"))

head(df_text)
```

Voici le processus général pour extraire plusieurs playlists YouTube :

```{r, eval = FALSE}
library(lexico)
yt_dlp  <- Sys.getenv("YT_DLP_PATH")
api_key <- Sys.getenv("YT_API_KEY")

max_videos  <- 5
workdir <- file.path(tempdir(),"data")

df_playlist <- dplyr::tibble(
                 suffix = "bfm",
                 channelTitle = "BFMTV",
                 playlist_id = "PL-qBKb-rfbhjZjW0RQr3Dm8iIvXFE0Gwy",
                 playlistDescription = "Politique") %>%
  dplyr::add_row(suffix = "fra",
                 channelTitle = "franceinfo",
                 playlist_id = "PLg6GanYvTasWQv6EPyPInaYhtyFRcht3r",
                 playlistDescription = "Interview de 8:30")

1:nrow(df_playlist) %>% purrr::map(~{
  row <- df_playlist[.x,]
  cli::cli_alert_info("Extraction {row$playlistDescription}")
  run_complete_extraction(api_key,yt_dlp,workdir,
                          row$suffix,row$playlist_id,max_videos)
})

```

La fonction run_complete_extraction crée trois fichiers pour chaque playlist : df_info, df_stat, df_text. Dans le même répertoire se trouve également un répertoire avec tous les fichiers vtt de sous-titres.

Ces bases de données peuvent ensuite être nettoyées et enrichies avant d'être utilisées
dans les autres vignettes (préparation, IRaMuTeQ, Quanteda).
