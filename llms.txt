# lexico

Package R pour faciliter l’extraction et l’analyse lexicométrique de
contenus vidéo YouTube. Il combine des utilitaires de scraping (API
YouTube + sous-titres via `yt-dlp`) et des fonctions de
préparation/normalisation pour travailler ensuite avec *quanteda* ou
exporter/importer des corpus au format *IRaMuTeQ*.

## Installation

L’installation se fait directement via mon github. Aucune diffusion sur
CRAN n’est prévue à ce stade.

``` r
remotes::install_github("tdelc/lexico")
```

## Prérequis

- Une clé API YouTube Data (v3) pour interroger les playlists et vidéos.
- L’outil en ligne de commande
  [`yt-dlp`](https://github.com/yt-dlp/yt-dlp) disponible dans le `PATH`
  pour télécharger les sous-titres.
- R (avec les dépendances déclarées dans `DESCRIPTION`, notamment
  `quanteda`, `dplyr`, `httr`, `purrr`, `stringr`, `stopwords`).

Aucune donnée n’est distribuée avec le package : seules les fonctions
sont fournies, le téléchargement restant à la charge de
l’utilisateur·rice.

## Fonctionnalités principales

### Scraping YouTube

- `get_playlist_items(api_key, playlist_id, max_results = 100)`:
  récupère les métadonnées d’une playlist (titre, description, date de
  publication, position, etc.).
- `get_videos_details(api_key, video_ids)`: complète les informations
  des vidéos (statistiques, durée, langue, tags…).
- `download_subtitles(video_id, out_dir, yt_dlp = "yt-dlp", force_dl = FALSE)`:
  télécharge les sous-titres automatiques français d’une vidéo.
- `read_vtt_as_text(vtt_file)`: transforme un fichier `.vtt` en texte
  brut agrégé.
- `run_complete_extraction(api_key, path, suffix, playlist_id, max_videos)`:
  pipeline clé en main pour une playlist : récupération des infos/
  stats, téléchargement des sous-titres, consolidation en CSV.
- `parse_yt_duration(duration)`: convertit la durée YouTube (ex.
  `"PT25M31S"`) en secondes.

### Préparation et nettoyage

- `clean_df_text(vec_text, recode_words, stopwords, multiwords)`:
  normalise les textes (suppression de stopwords spécifiques, recodage,
  composition de multi-mots).
- Lexique et règles prêtes à l’emploi :
  [`get_specific_stopwords()`](https://tdelc.github.io/lexico/reference/get_specific_stopwords.md),
  [`get_specific_multiwords()`](https://tdelc.github.io/lexico/reference/get_specific_multiwords.md),
  [`get_recode_words()`](https://tdelc.github.io/lexico/reference/get_recode_words.md),
  [`remove_apostrophe()`](https://tdelc.github.io/lexico/reference/remove_apostrophe.md).

### Quanteda

- `corpus_to_tokens(corpus, recode_words, stopwords, multiwords)`:
  convertit un corpus `quanteda` en tokens propres (minuscules, retrait
  ponctuation, URLs, nombres, stopwords, recodage, multi-mots).
- [`get_dictionary()`](https://tdelc.github.io/lexico/reference/get_dictionary.md):
  dictionnaire thématique (immigration, sécurité, identité, etc.) prêt
  pour
  [`quanteda::dfm_lookup`](https://quanteda.io/reference/dfm_lookup.html).

### IRaMuTeQ

- `export_to_iramuteq(df, meta_cols, text_col, output_file)`: crée un
  fichier texte structuré pour IRaMuTeQ à partir d’un data.frame
  (métadonnées en en-tête `****`).
- `import_from_iramuteq(file)`: lit un export IRaMuTeQ et reconstruit un
  data.frame (métadonnées + texte).

## Exemple de flux complet

``` r
api_key <- Sys.getenv("YOUTUBE_API_KEY")
playlist_id <- "PLxxxxxxxxxxxxxxxx"
base_dir <- "data"

# 1. Scraper les infos + sous-titres de la playlist
run_complete_extraction(
  api_key = api_key,
  path = base_dir,
  suffix = "ma_chaine",
  playlist_id = playlist_id,
  max_videos = 200
)

# 2. Charger les textes et nettoyer
subs_dir <- file.path(base_dir, "subs_ma_chaine")
vtt_files <- list.files(subs_dir, pattern = "\\.vtt$", full.names = TRUE)
text_df <- purrr::map_dfr(vtt_files, read_vtt_as_text)

# 3. Tokeniser puis créer une DFM avec dictionnaire thématique
corp <- quanteda::corpus(text_df, text_field = "text_clean")
toks <- corpus_to_tokens(corp)
dfm <- quanteda::dfm(toks)
quanteda::dfm_lookup(dfm, dictionary = get_dictionary())

# 4. Exporter vers IRaMuTeQ si besoin
export_to_iramuteq(text_df, meta_cols = "video_id", text_col = "text_clean", output_file = "iramuteq.txt")
```

## Bonnes pratiques

- Respectez les quotas de l’API YouTube et stockez votre clé dans une
  variable d’environnement.
- [`download_subtitles()`](https://tdelc.github.io/lexico/reference/download_subtitles.md)
  accepte `force_dl = TRUE` pour forcer la mise à jour des sous-titres.
- Les multi-mots sont enregistrés avec `_` pour les conserver lors de
  l’analyse lexicométrique.

## Licence

Les codes sont publics sous licence gpl3; aucune donnée n’est distribuée
avec le package.

# Package index

## All functions

- [`clean_df_text()`](https://tdelc.github.io/lexico/reference/clean_df_text.md)
  : Clean a text variable of a df
- [`col2hex()`](https://tdelc.github.io/lexico/reference/col2hex.md) :
  Convert color to hexadecimal
- [`color_emotions()`](https://tdelc.github.io/lexico/reference/color_emotions.md)
  : Color gt with emotions
- [`color_polarity()`](https://tdelc.github.io/lexico/reference/color_polarity.md)
  : Color gt with polarity
- [`corpus_to_tokens()`](https://tdelc.github.io/lexico/reference/corpus_to_tokens.md)
  : Convert quanteda corpus to tokens
- [`download_subtitles()`](https://tdelc.github.io/lexico/reference/download_subtitles.md)
  : Download subtitles from a youtube video
- [`export_to_iramuteq()`](https://tdelc.github.io/lexico/reference/export_to_iramuteq.md)
  : Export to iramuteq
- [`format_emotions()`](https://tdelc.github.io/lexico/reference/format_emotions.md)
  : Format gt with emotions
- [`format_polarity()`](https://tdelc.github.io/lexico/reference/format_polarity.md)
  : Format gt with polarity
- [`get_dictionary()`](https://tdelc.github.io/lexico/reference/get_dictionary.md)
  : Get quanteda dictionary with preset terms
- [`get_dominant_emotion()`](https://tdelc.github.io/lexico/reference/get_dominant_emotion.md)
  : Get most frequent emotion of a sentiment score df
- [`get_dominant_polarity()`](https://tdelc.github.io/lexico/reference/get_dominant_polarity.md)
  : Get most frequent polarity of a sentiment score df
- [`get_playlist_items()`](https://tdelc.github.io/lexico/reference/get_playlist_items.md)
  : Get youtube infos from a playlist
- [`get_recode_words()`](https://tdelc.github.io/lexico/reference/get_recode_words.md)
  : get recoding words
- [`get_specific_multiwords()`](https://tdelc.github.io/lexico/reference/get_specific_multiwords.md)
  : Get specific multiwords for the study
- [`get_specific_stopwords()`](https://tdelc.github.io/lexico/reference/get_specific_stopwords.md)
  : Specific stopwords for this study
- [`get_videos_details()`](https://tdelc.github.io/lexico/reference/get_videos_details.md)
  : Get details from youtube videos
- [`group_minuted_text()`](https://tdelc.github.io/lexico/reference/group_minuted_text.md)
  : Regroup text by minutes
- [`hms_to_sec()`](https://tdelc.github.io/lexico/reference/hms_to_sec.md)
  : Convert hour:minutes:secondes to secondes
- [`import_from_iramuteq()`](https://tdelc.github.io/lexico/reference/import_from_iramuteq.md)
  : import df from iramuteq
- [`label_emotions()`](https://tdelc.github.io/lexico/reference/label_emotions.md)
  : Label gt with emotions
- [`label_polarity()`](https://tdelc.github.io/lexico/reference/label_polarity.md)
  : Label gt with polarity
- [`lexico_example()`](https://tdelc.github.io/lexico/reference/lexico_example.md)
  : Obtain extdata for the lexico package
- [`parse_yt_duration()`](https://tdelc.github.io/lexico/reference/parse_yt_duration.md)
  : Get duration of a youtube video
- [`read_iramuteq_class()`](https://tdelc.github.io/lexico/reference/read_iramuteq_class.md)
  : Read report from iramuteq to extract words of each class
- [`read_vtt_as_df()`](https://tdelc.github.io/lexico/reference/read_vtt_as_df.md)
  : Convert subtitles file to minuted data.frame
- [`read_vtt_as_text()`](https://tdelc.github.io/lexico/reference/read_vtt_as_text.md)
  : Convert subtitles file to text (OLD)
- [`remove_apostrophe()`](https://tdelc.github.io/lexico/reference/remove_apostrophe.md)
  : Correct apostrophe
- [`run_complete_extraction()`](https://tdelc.github.io/lexico/reference/run_complete_extraction.md)
  : Run a complete extraction for a playlist id
- [`summarise_emotions()`](https://tdelc.github.io/lexico/reference/summarise_emotions.md)
  : Summarise emotions of a data.frame
- [`summarise_polarity()`](https://tdelc.github.io/lexico/reference/summarise_polarity.md)
  : Summarise polarity of a data.frame
- [`treemap_double_classe()`](https://tdelc.github.io/lexico/reference/treemap_double_classe.md)
  : Plot a treemap of thema and classe of segments
- [`vtt_files_to_df()`](https://tdelc.github.io/lexico/reference/vtt_files_to_df.md)
  : Convert vtt files to minuted data.frame

# Articles

### All vignettes

- [Scraper des playlists
  YouTube](https://tdelc.github.io/lexico/articles/00_scraping.md):
- [Préparer les données
  textuelles](https://tdelc.github.io/lexico/articles/01_prepa-data.md):
- [Préparer et exploiter des corpus avec
  IRaMuTeQ](https://tdelc.github.io/lexico/articles/02_iramuteq.md):
- [Analyser les textes avec
  Quanteda](https://tdelc.github.io/lexico/articles/03_quanteda.md):
